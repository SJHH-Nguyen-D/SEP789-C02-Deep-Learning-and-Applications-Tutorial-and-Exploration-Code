{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RL.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "P1VdBJun8nyx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# SEP789-CO2 Deep Learning and Applications\n",
        "\n",
        "# Lecture 4  - Reinforcement Learning\n",
        "\n",
        "Below is an in-class toy example, exploring some of the functionality that the gym module offers. I doesn't cover any of the nifty gaming toy example code, however it does give us some idea of how an agency can navigate an environment, given a simple policy to maximize some of the rewards."
      ]
    },
    {
      "metadata": {
        "id": "EKPh_Sph8nQO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "random.seed(145)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8smHbdq1Jc2T",
        "colab_type": "code",
        "outputId": "4776c8c4-c2b1-473e-d716-68f5188cc9a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "help(gym.make)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on function make in module gym.envs.registration:\n",
            "\n",
            "make(id, **kwargs)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ep9UEqYO2ilK",
        "colab_type": "code",
        "outputId": "545e5c91-f8bf-4347-d6c0-906153790d09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "cell_type": "code",
      "source": [
        "env=gym.make(\"NChain-v0\")\n",
        "env.reset()\n",
        "\n",
        "for item in range(20):\n",
        "  input1=np.random.randint(0, 2)\n",
        "  print(\"Input {enter} ==> State: {output}\"\n",
        "        .format(enter=input1,output=env.step(input1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input 0 ==> State: (0, 2, False, {})\n",
            "Input 0 ==> State: (0, 2, False, {})\n",
            "Input 1 ==> State: (0, 2, False, {})\n",
            "Input 1 ==> State: (0, 2, False, {})\n",
            "Input 1 ==> State: (0, 2, False, {})\n",
            "Input 1 ==> State: (1, 0, False, {})\n",
            "Input 0 ==> State: (0, 2, False, {})\n",
            "Input 1 ==> State: (1, 0, False, {})\n",
            "Input 0 ==> State: (2, 0, False, {})\n",
            "Input 1 ==> State: (0, 2, False, {})\n",
            "Input 1 ==> State: (0, 2, False, {})\n",
            "Input 1 ==> State: (0, 2, False, {})\n",
            "Input 1 ==> State: (1, 0, False, {})\n",
            "Input 1 ==> State: (0, 2, False, {})\n",
            "Input 1 ==> State: (0, 2, False, {})\n",
            "Input 0 ==> State: (1, 0, False, {})\n",
            "Input 0 ==> State: (2, 0, False, {})\n",
            "Input 0 ==> State: (3, 0, False, {})\n",
            "Input 0 ==> State: (4, 0, False, {})\n",
            "Input 1 ==> State: (0, 2, False, {})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GZrf0hnALtIe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def naive_sum_reward_agent(env, num_episodes=500):\n",
        "    # number of episodes (or number of games) that we will train the r_table on. \n",
        "    # this is the table to hold our summated rewards for\n",
        "    # each action in each state\n",
        "    r_table = np.zeros((5, 2))\n",
        "    for g in range(num_episodes):\n",
        "        state = env.reset()\n",
        "        done = False\n",
        "        while not done:\n",
        "            if np.sum(r_table[state, :]) == 0:\n",
        "                # make a random selection of actions\n",
        "                action = np.random.randint(0, 2)\n",
        "            else:\n",
        "                # select the action with highest cummulative reward\n",
        "                action = np.argmax(r_table[state, :])\n",
        "            new_state, reward, done, _ = env.step(action)\n",
        "            r_table[state, action] += reward\n",
        "            state = new_state\n",
        "    return r_table"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yY3cQO3OJ9Pw",
        "colab_type": "code",
        "outputId": "943913d1-8533-4eee-fe0d-037493d4bbbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "a = np.random.randint(0,2)\n",
        "a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "metadata": {
        "id": "LKagVJe5psfZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "help(np.argmax)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IlC58IiBvjSq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def q_learning_with_table(env, num_episodes=500):\n",
        "    q_table = np.zeros((5, 2))\n",
        "    gamma = 0.95    #discounting factor\n",
        "    alpha = 0.8     # learning rate \n",
        "    for i in range(num_episodes):\n",
        "        state = env.reset()\n",
        "        done = False\n",
        "        while not done:\n",
        "            if np.sum(q_table[state,:]) == 0:\n",
        "                # make a random selection of actions\n",
        "                action = np.random.randint(0, 2)\n",
        "            else:\n",
        "                # select the action with largest q value in state s\n",
        "                action = np.argmax(q_table[state, :])\n",
        "            new_state, reward, done, _ = env.step(action)\n",
        "            q_table[state, action] += reward + alpha*(gamma*np.max(q_table[new_state, :]) - q_table[state, action])\n",
        "            state = new_state\n",
        "    return q_table"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z_alwaVHxoLo",
        "colab_type": "code",
        "outputId": "328f32e4-fb8b-49bd-d76f-3c1aa671758c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        " q_learning_with_table(env)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        , 25.32889595],\n",
              "       [ 0.        , 25.74424155],\n",
              "       [25.9253106 ,  0.        ],\n",
              "       [ 0.        , 27.03811544],\n",
              "       [32.04603017,  0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "YzeBJluC2JAL",
        "colab_type": "code",
        "outputId": "608aeb0d-b63d-42b5-f72b-5afd4207d848",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "def eps_greedy_q_learning_with_table(env, num_episodes=500):\n",
        "    q_table = np.zeros((5, 2))\n",
        "    y = 0.95\n",
        "    eps = 0.5\n",
        "    lr = 0.8\n",
        "    decay_factor = 0.999\n",
        "    for i in range(num_episodes):\n",
        "        s = env.reset()\n",
        "        eps *= decay_factor\n",
        "        done = False\n",
        "        while not done:\n",
        "            # select the action with highest cummulative reward\n",
        "            if np.random.random() < eps or np.sum(q_table[s, :]) == 0:\n",
        "                a = np.random.randint(0, 2)\n",
        "            else:\n",
        "                a = np.argmax(q_table[s, :])\n",
        "            # pdb.set_trace()\n",
        "            new_s, r, done, _ = env.step(a)\n",
        "            q_table[s, a] += r + lr * (y * np.max(q_table[new_s, :]) - q_table[s, a])\n",
        "            s = new_s\n",
        "    return q_table\n",
        "eps_greedy_q_learning_with_table(env)  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 41.34997513,  43.2341573 ],\n",
              "       [ 41.56352904,  43.62565772],\n",
              "       [ 90.1352202 ,  43.08038954],\n",
              "       [126.08341365,  42.90258552],\n",
              "       [154.61812196,  47.30556732]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "metadata": {
        "id": "rVB7AI453Qxh",
        "colab_type": "code",
        "outputId": "e1522162-d734-4cf3-c9a5-284fa2fc1542",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "\n",
        "\n",
        "def test_methods(env, num_iterations=100):\n",
        "    winner = np.zeros((3,))\n",
        "    for g in range(num_iterations):\n",
        "        m0_table = naive_sum_reward_agent(env, 500)\n",
        "        m1_table = q_learning_with_table(env, 500)\n",
        "        m2_table = eps_greedy_q_learning_with_table(env, 500)\n",
        "        m0 = run_game(m0_table, env)\n",
        "        m1 = run_game(m1_table, env)\n",
        "        m2 = run_game(m2_table, env)\n",
        "        w = np.argmax(np.array([m0, m1, m2]))\n",
        "        winner[w] += 1\n",
        "        print(\"Game {} of {}\".format(g + 1, num_iterations))\n",
        "    return winner\n",
        "def run_game(table, env):\n",
        "    s = env.reset()\n",
        "    tot_reward = 0\n",
        "    done = False\n",
        "    while not done:\n",
        "        a = np.argmax(table[s, :])\n",
        "        s, r, done, _ = env.step(a)\n",
        "        tot_reward += r\n",
        "    return tot_reward\n",
        "\n",
        "start = timeit.default_timer()\n",
        "test_methods(env, num_iterations=20)  \n",
        "end = timeit.default_timer()\n",
        "\n",
        "print(end-start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Game 1 of 20\n",
            "Game 2 of 20\n",
            "Game 3 of 20\n",
            "Game 4 of 20\n",
            "Game 5 of 20\n",
            "Game 6 of 20\n",
            "Game 7 of 20\n",
            "Game 8 of 20\n",
            "Game 9 of 20\n",
            "Game 10 of 20\n",
            "Game 11 of 20\n",
            "Game 12 of 20\n",
            "Game 13 of 20\n",
            "Game 14 of 20\n",
            "Game 15 of 20\n",
            "Game 16 of 20\n",
            "Game 17 of 20\n",
            "Game 18 of 20\n",
            "Game 19 of 20\n",
            "Game 20 of 20\n",
            "401.83902745399973\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}